\section{Constrained optimization of functionals of the form $H[f(x)]$}

In this lecture, we extend the concepts learned in the previous lecture to look at {\it constrained} optimization. As we shall see, we can once again easily extend tools of multivariate Calculus to do so. First of all, let's review how to solve constrained optimization problems for multivariate functions.

\subsection{The method of Lagrange multipliers in multivariate Calculus}

Suppose we wish to optimize (minimize or maximize) a multivariate function $f({\bf x})$ where ${\bf x}$ is an $N$-dimensional vector, {\it subject to the constraint} that $c({\bf x}) = 0$. Here, the functions $f({\bf x})$ and $c({\bf x})$ are known, and we are looking for the optimal points ${\bf x}$. 

The constraint $c({\bf x}) = 0$ generally forms an $N-1$ dimensional subspace (sometimes called manifold) in the $N$-dimensional space. For instance:
\begin{itemize}
    \item The constraint $x=1$, which we can write as $c(x) = x-1 = 0$ forms a line on the 2D Cartesian space
    \item The constraint $r =1$, which we can write $c(x,y,z) = \sqrt{x^2+y^2+z^2} -1 = 0$ forms the surface of a sphere in 3D space. 
\end{itemize}

It is easy to convince oneself with a simple figure that maximizing or minimizing $f$ subject to the constraint $c({\bf x}) = 0$  boils down to finding the points where the isocontours of $f$ are tangent to the curve/surface/etc. described by the constraint. 
\\
\\
{\color{red} {\bf Add figure}}
\\
\\
Isocontours of $f$ being tangent to the constraint curve (which is the 0 isocontour of $c$), simply implies that $\nabla f$ is parallel to $\nabla c$ (because $\nabla f$ and $\nabla c$ are perpendicular to the isocontours of $f$ and $c$, respectively). 

To find the points where this happens, we therefore find all of the solutions of the system of equations formed by 
\begin{eqnarray}
 c({\bf x}) = 0 \\
 \nabla f = \mu \nabla c 
 \end{eqnarray}
for some $\mu$ (that is also to be found as part of the solution). The scalar $\mu$ is called the {\it Lagrange Multiplier}. 
Let's look at a few examples.
\\
\\
{\bf Example 1:} What is the shortest distance between the origin and the plane $z = 1-x-y$? 
\\
\\
{\color{red} {\bf Solution: }}
\\
\\
Note that we can also try to solve problems with multiple constraints -- we simply add each of them with its own Lagrange multiplier.
\\
\\
{\bf Example 2:} Find the stationary points of $f(x,y,z) = x^3 + y^3 + z^3$ subject to the two constraints $x^2 + y^2 + z^2 = 1$ and $x+y+z = 0$.  
\\
\\
{\color{red} {\bf Solution: }}
\\
\\

\subsection{Constrained optimization of functionals}

Drawing again on the analogy that views functional derivatives as a continuum version of the gradient, we can see that in order to optimize a functional $H[f(x)]$, subject to the constraint that some other functional $C[f(x)] = 0$, can be done by requiring at the same time that
\begin{eqnarray}
    C[f(x)] = 0 \\
    \frac{\delta H}{\delta f} = \mu \frac{\delta C}{\delta f}
    \end{eqnarray}
Let's see a few examples. 
\\
\\
{\bf Example 1: The catenary curve.} A catenary curve is the shape that a hanging chain or a hanging necklace of a given length takes when held at two points at the same height. Physically speaking, that is the shape adopted by the chain as it minimizes potential energy. To find it requires solving a constrained optimization problem involving functionals. To see this, suppose that the shape of the chain is given by $y = f(x)$, and that the chain is held at $y = 0$ at both $x = 0$ and $x = 1$. Then we know that 
\begin{itemize}
\item The length of the chain is fixed and equal to $L_C$, therefore 
$$ 
L_C = \int_0^1 \sqrt{1+f'^2} dx 
$$
\item The potential energy of the chain is equal to 
$$
P[f(x)] = \int_0^1 \rho g f dx 
$$
\end{itemize}
We therefore want to miminize $P[f(x)]$ subject to the constraint 
\begin{equation}
    C[f(x)] = \int_0^1 \sqrt{1+f'^2} dx  - L_C =\int_0^1 \left[ \sqrt{1+f'^2} - L_C \right] dx   = 0
 \end{equation}
\\
\\
{\bf \color{red} Solution:}
\\
\\
{\bf Example 2: Dido's problem} Show that the only possible (smooth) closed, simply connected curve of given perimeter $P$ that maximizes a given area $A$ is a circle. 
\begin{itemize}
    \item Consider a point O somewhere inside the curve, and define the equation of the curve in polar coordinates as $r = f(\theta)$ where $\theta \in [0,2\pi]$, and $r$ is the distance from the point O to the curve.
    \item Write down the area and the perimeter of the curve as functionals of $r(\theta)$. \item Construct the optimization problem, and solve it. 
\end{itemize}
\\
\\
{\bf \color{red} Solution:}

